{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Environment Setup\n",
    "\n",
    "### 1.1 Import Standard Libraries\n",
    "\n",
    "Import all necessary libraries at the beginning. Group imports logically and follow PEP 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Genesis 22 Canonical Notebook Template - Imports\n",
    "\n",
    "This cell demonstrates proper import organization:\n",
    "- Standard library imports first\n",
    "- Third-party imports second\n",
    "- Local/custom imports last\n",
    "- Grouped and alphabetized within each section\n",
    "\"\"\"\n",
    "\n",
    "# Standard Library\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "# Third-Party: Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Third-Party: Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Third-Party: Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Third-Party: Utilities\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configure warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "# Print versions for reproducibility\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"Matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn: {sns.__version__}\")\n",
    "print(f\"Notebook executed at: {datetime.now().isoformat()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Project configuration and constants.\"\"\"\n",
    "\n",
    "# Paths (use pathlib for cross-platform compatibility)\n",
    "PROJECT_ROOT: Path = Path.cwd()\n",
    "DATA_DIR: Path = PROJECT_ROOT / \"data\"\n",
    "RAW_DATA_DIR: Path = DATA_DIR / \"raw\"\n",
    "PROCESSED_DATA_DIR: Path = DATA_DIR / \"processed\"\n",
    "MODELS_DIR: Path = PROJECT_ROOT / \"models\"\n",
    "OUTPUTS_DIR: Path = PROJECT_ROOT / \"outputs\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [DATA_DIR, RAW_DATA_DIR, PROCESSED_DATA_DIR, MODELS_DIR, OUTPUTS_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Analysis Parameters\n",
    "RANDOM_STATE: int = 42\n",
    "TEST_SIZE: float = 0.2\n",
    "CONFIDENCE_LEVEL: float = 0.95\n",
    "\n",
    "# Visualization\n",
    "FIGURE_DPI: int = 300\n",
    "COLOR_PALETTE: List[str] = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "# Display paths for verification\n",
    "print(\"ðŸ“ Directory Structure:\")\n",
    "print(f\"  Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"  Data Directory: {DATA_DIR}\")\n",
    "print(f\"  Outputs Directory: {OUTPUTS_DIR}\")\n",
    "print(f\"\\nâš™ï¸  Configuration:\")\n",
    "print(f\"  Random State: {RANDOM_STATE}\")\n",
    "print(f\"  Test Size: {TEST_SIZE}\")\n",
    "print(f\"  Confidence Level: {CONFIDENCE_LEVEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate synthetic dataset for demonstration.\"\"\"\n",
    "\n",
    "def generate_sample_data(n_samples: int = 1000, random_state: int = RANDOM_STATE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a synthetic dataset for demonstration.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int, default=1000\n",
    "        Number of samples to generate\n",
    "    random_state : int, default=RANDOM_STATE\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Generated dataset with features and target\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Generate features\n",
    "    feature_1 = np.random.normal(loc=50, scale=15, size=n_samples)\n",
    "    feature_2 = np.random.exponential(scale=2, size=n_samples)\n",
    "    feature_3 = np.random.uniform(low=0, high=100, size=n_samples)\n",
    "    feature_4 = np.random.poisson(lam=5, size=n_samples)\n",
    "    \n",
    "    # Generate target with some relationship to features\n",
    "    noise = np.random.normal(loc=0, scale=10, size=n_samples)\n",
    "    target = (\n",
    "        2.5 * feature_1 + \n",
    "        1.8 * feature_2 - \n",
    "        0.5 * feature_3 + \n",
    "        3.2 * feature_4 + \n",
    "        noise\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'feature_1': feature_1,\n",
    "        'feature_2': feature_2,\n",
    "        'feature_3': feature_3,\n",
    "        'feature_4': feature_4,\n",
    "        'target': target,\n",
    "        'category': np.random.choice(['A', 'B', 'C'], size=n_samples),\n",
    "        'timestamp': pd.date_range(start='2024-01-01', periods=n_samples, freq='H')\n",
    "    })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generate dataset\n",
    "df_raw = generate_sample_data(n_samples=1000)\n",
    "\n",
    "print(f\"âœ… Dataset generated: {df_raw.shape[0]} rows Ã— {df_raw.shape[1]} columns\")\n",
    "print(f\"\\nðŸ“Š First few rows:\")\n",
    "display(df_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Comprehensive data validation and quality assessment.\"\"\"\n",
    "\n",
    "def validate_data(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Perform comprehensive data validation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame to validate\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Any]\n",
    "        Validation report with metrics and issues\n",
    "    \"\"\"\n",
    "    report = {}\n",
    "    \n",
    "    # Basic statistics\n",
    "    report['n_rows'] = len(df)\n",
    "    report['n_columns'] = len(df.columns)\n",
    "    report['memory_usage_mb'] = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    \n",
    "    # Missing values\n",
    "    report['missing_values'] = df.isnull().sum().to_dict()\n",
    "    report['missing_percentage'] = (df.isnull().sum() / len(df) * 100).to_dict()\n",
    "    \n",
    "    # Duplicates\n",
    "    report['n_duplicates'] = df.duplicated().sum()\n",
    "    \n",
    "    # Data types\n",
    "    report['dtypes'] = df.dtypes.astype(str).to_dict()\n",
    "    \n",
    "    # Numeric columns statistics\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    report['numeric_columns'] = list(numeric_cols)\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Validate the dataset\n",
    "validation_report = validate_data(df_raw)\n",
    "\n",
    "print(\"ðŸ” Data Validation Report\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dimensions: {validation_report['n_rows']:,} rows Ã— {validation_report['n_columns']} columns\")\n",
    "print(f\"Memory Usage: {validation_report['memory_usage_mb']:.2f} MB\")\n",
    "print(f\"Duplicates: {validation_report['n_duplicates']}\")\n",
    "print(f\"\\nðŸ“‹ Data Types:\")\n",
    "for col, dtype in validation_report['dtypes'].items():\n",
    "    print(f\"  {col}: {dtype}\")\n",
    "print(f\"\\nâŒ Missing Values:\")\n",
    "for col, count in validation_report['missing_values'].items():\n",
    "    if count > 0:\n",
    "        pct = validation_report['missing_percentage'][col]\n",
    "        print(f\"  {col}: {count} ({pct:.2f}%)\")\n",
    "if sum(validation_report['missing_values'].values()) == 0:\n",
    "    print(\"  âœ… No missing values detected\")\n",
    "\n",
    "# Display descriptive statistics\n",
    "print(\"\\nðŸ“Š Descriptive Statistics:\")\n",
    "display(df_raw.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data Validation and Quality Checks\n",
    "\n",
    "Perform comprehensive validation to ensure data integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Loading & Validation\n",
    "\n",
    "### 2.1 Generate Sample Dataset\n",
    "\n",
    "For demonstration purposes, we'll generate a synthetic dataset. In real projects, replace this with actual data loading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define Constants and Configuration\n",
    "\n",
    "Centralize all configuration values and magic numbers as named constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Configure display settings for optimal notebook experience.\"\"\"\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "\n",
    "# Matplotlib style and settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "# Seaborn settings\n",
    "sns.set_palette(\"husl\")\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable autoreload for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"âœ… Display settings configured successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configure Display Settings\n",
    "\n",
    "Set up notebook display preferences for optimal readability and presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genesis 22 Canonical Notebook Template\n",
    "\n",
    "**Author**: Genesis 22 Project  \n",
    "**Date**: 2025-10-11  \n",
    "**Version**: 1.0.0  \n",
    "**Python Version**: 3.12+\n",
    "\n",
    "This notebook serves as the **flagship example** and **canonical template** for all Jupyter notebook work in the Genesis 22 project.\n",
    "\n",
    "## Features Demonstrated\n",
    "\n",
    "- âœ… Proper notebook structure and organization\n",
    "- âœ… Clear documentation and markdown usage\n",
    "- âœ… Type hints and code quality standards\n",
    "- âœ… Reproducible data analysis workflow\n",
    "- âœ… Professional visualization practices\n",
    "- âœ… Error handling and validation\n",
    "- âœ… Memory-efficient coding patterns\n",
    "\n",
    "## ðŸ“‹ Table of Contents\n",
    "\n",
    "1. [Environment Setup](#1-environment-setup)\n",
    "2. [Data Loading & Validation](#2-data-loading--validation)\n",
    "3. [Exploratory Data Analysis](#3-exploratory-data-analysis)\n",
    "4. [Statistical Analysis](#4-statistical-analysis)\n",
    "5. [Visualization](#5-visualization)\n",
    "6. [Results & Conclusions](#6-results--conclusions)\n",
    "7. [Cleanup & Best Practices](#7-cleanup--best-practices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
